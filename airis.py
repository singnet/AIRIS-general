import copy
import heapq
import hashlib
import uuid
import json
from difflib import SequenceMatcher
from functools import reduce
import logging
from datetime import datetime
from random import choice
from random import shuffle

def serialize_sets(obj):
    if isinstance(obj, set):
        return list(obj)

    return obj

class Airis:
    def __init__(self, knowledge_json, state_graph_json):

        # inputs are dictionaries containing the input from the environment and any optional meta data

        # 's_input' is structured data
        # Structured data is data that has a fixed size and the index of the data is contextually relevant
        #   example of a structured 4 index action bar:
        #       s_input['action bar'] = (('Battery', 4), None, ('Key', 'Yellow', 1), None)
        self.s_input = dict()

        # 'u_input' is unstructured data
        # Unstructured data is data of varying size where the index of the data is contextually irrelevant
        #   example of an unstructured 7 index state as ([object name], [object type], ([state], [state], ...), [distances from NPC]):
        #       u_input['objects'] = (('light switch 1', 'light switch', (‘off’), 30.5), ('door switch 1', 'door switch', (‘locked’), 50.67), ('door 1', 'door', (‘closed’), 52.0), ('door switch 2', 'door switch', (‘locked’), 53.67), ('chair 4', 'chair', ('empty'), 70.0), ('UltraGamer907', 'player', ('idle'), 34.0), ('generator', 'generator', (.75), 45.0))
        self.u_input = dict()

        # 'actions' is a dictionary available actions with any optional arguments nested within
        # This dictionary can be dynamic based on the available actions at a given time
        # The first level of keys is used to select actions
        # Each key at the first level represents an action that can be taken simultaneously with other keys at this level (if applicable)
        # A tuple argument represents a continuous range
        # A list argument represents discrete options
        # A dictionary argument represents additional arguments that can be provided for the parent argument
        #   examples of some actions:
        #       actions = {
        #           'Use Item': {
        #               ('Battery', 4): {
        #                   'generator': [1],
        #                   'chair': [1]
        #               }
        #           }
        #
        #           'Move': {
        #               (0, 360): (0, 1)
        #           }
        #       }
        self.actions = dict()

        # 'knowledge' is a dictionary that contains the rules generated by AIRIS.
        # If knowledge_json (stored knowledge from a previous session) is not "None", then it will load the knowledge json
        if knowledge_json:
            self.knowledge = json.loads(knowledge_json)
        else:
            self.knowledge = dict()

        # 'state_graph' is a dictionary that contains each states data
        # State data consists of all inputs, actions, and any outgoing edges
        # The key is the hash of all inputs and actions
        # If state_graph_json (stored state graph from a previous session) is not "None", then it will load the state graph json
        if state_graph_json:
            self.state_graph = json.loads(state_graph_json)
        else:
            self.state_graph = dict()

        # 'action_plan' is the action(s) to return to the environment to perform
        self.action_plan = []

        # 'tasks' are the current tasks (or goals)
        # If there are no tasks specified, AIRIS will default to curiousity driven exploration
        # Tasks are dynamic and can be changed at any time
        # Tasks types are 'Increase', 'Decrease', and 'Match'
        # Tasks can be given a priority. The priority closest to 1 is the highest. A priority of 0 has no priority. Tasks can have equal priority.
        # No priority tasks are opportunistic. It will not seek out these tasks, but will perform them if the opportunity presents.
        # 'Increase' seeks to increase an input(s) by a given amount. If an amount of 0 is given, it will attempt to maximize the increase.
        #   'Increase' : ([structured / unstructured], [input key], [data index / first data index of unstructured list], [index of data to change], [amount], [priority])
        # 'Decrease' seeks to decrease an input(s) by a given amount. If an amount of 0 is given, it will attempt to maximize the decrease.
        #   'Decrease' : ([structured / unstructured], [input key], [data index / first data index of unstructured list], [index of data to change], [amount], [priority])
        # 'Match' seeks to set an input(s) to a given value. This value can be of any type.
        #   'Match' : ([structured / unstructured / action], [input key / action key], [data index / first data index of unstructured list / primary action key], [index of data to match], [value], [priority])
        #   examples of some tasks:
        #       tasks = {
        #           'Increase': [('u', 'objects', 'generator', 2, 0, 1), ('s', 'action bar', 0, 1, 5, 2)] // Increase 'generator's first index as much as possible as priority 1, Increase the quantity of 'Battery' in action bar slot 0 to 5 as priority 2
        #           'Match': [('u', 'objects', 'light switch', 1, 'on', 0)] // Set the state of any 'light switch' to 'on' with no priority. The agent will turn on any light switches it comes across.
        #       }
        self.tasks = dict()

        # 'time_step' is the total time the agent has existed in perception steps
        self.time_step = 0

        self.action_taken = None
        self.prediction_state = None
        self.prediction_match = None

        self.log = logging.getLogger(__name__)
        self.init_time = datetime.now().strftime("%Y-%m-%d %H-%M-%S")
        logging.basicConfig(filename='airis logs/airis init ' + str(self.init_time) + '.log', encoding='utf-8', level=logging.DEBUG) #Enable to log to file
        self.log.info('AIRIS class initialized')

    def pre_capture_input(self, s_input, u_input, actions, tasks):
        # Update inputs and actions to current
        self.s_input = json.loads(s_input)
        self.u_input = json.loads(u_input)
        self.actions = json.loads(actions)
        self.tasks = json.loads(tasks)

        # self.log.debug('pre capture json data %s %s %s %s', self.s_input, self.u_input, self.actions, self.tasks)

        # print('pre_capture knowledge %s', self.knowledge)

        # Check if the current state is in the state graph. If not, create it
        state_hash = self.make_hash(self.s_input, self.u_input, self.actions)
        try:
            self.state_graph[state_hash]['grounded'] = True
        except KeyError:
            self.state_graph[state_hash] = dict()
            self.state_graph[state_hash]['s_input'] = self.s_input
            self.state_graph[state_hash]['u_input'] = self.u_input
            self.state_graph[state_hash]['actions'] = self.actions
            self.state_graph[state_hash]['compare'] = self.compare(state_hash, self.tasks)
            self.state_graph[state_hash]['edges'] = dict()
            self.state_graph[state_hash]['grounded'] = True

        # If there is no action plan, make one and return the first action in the plan
        if not self.action_plan:
            self.make_plan(state_hash)
            print('AIRIS: action plan', self.action_plan)
            self.action_taken, self.prediction_state, self.prediction_match, _ = self.action_plan.pop(0)
            return json.dumps(self.action_taken)
        # If there is an action plan, return the next action in the action plan
        else:
            self.action_taken, self.prediction_state, self.prediction_match, _ = self.action_plan.pop(0)
            return json.dumps(self.action_taken)

    def post_capture_input(self, p_s_input, p_u_input, p_actions):
        post_s_input = json.loads(p_s_input)
        post_u_input = json.loads(p_u_input)
        post_actions = json.loads(p_actions)
        # self.log.debug('post capture json data %s %s %s', post_s_input, post_u_input, post_actions)
        act = self.action_taken
        prediction_state = self.prediction_state
        prediction_match = self.prediction_match
        self.time_step += 1
        # Check if the new state is in the state graph. If not, create it
        post_state_hash = self.make_hash(post_s_input, post_u_input, post_actions)
        try:
            self.state_graph[post_state_hash]['grounded'] = True
        except KeyError:
            self.state_graph[post_state_hash] = dict()
            self.state_graph[post_state_hash]['s_input'] = copy.deepcopy(post_s_input)
            self.state_graph[post_state_hash]['u_input'] = copy.deepcopy(post_u_input)
            self.state_graph[post_state_hash]['actions'] = copy.deepcopy(post_actions)
            self.state_graph[post_state_hash]['compare'] = self.compare(post_state_hash, self.tasks)
            self.state_graph[post_state_hash]['edges'] = dict()
            self.state_graph[post_state_hash]['grounded'] = True

        # Check for mismatches between the predicted state and the new state
        s_mismatch_result = []
        u_mismatch_result = []

        # Check for Structured Data mismatches as (key, index path, old value, new value)
        s_path = []
        for key in self.s_input.keys():
            s_heap = []
            for idx, val in enumerate(self.s_input[key]):
                if isinstance(val, list):
                    heapq.heappush(s_heap, [idx])
                while s_heap:
                    origin = self.fetch_input(self.s_input[key], *s_heap[0])
                    for ii, vv in enumerate(origin):
                        path = copy.copy(s_heap[0])
                        path.append(ii)
                        if isinstance(origin[ii], list):
                            heapq.heappush(s_heap, path)
                        else:
                            nv = self.fetch_input(post_s_input[key], *path)
                            s_path.append((key, path, vv, nv))
                            pv = self.fetch_input(self.state_graph[prediction_state]['s_input'][key], *path)
                            if nv != pv:
                                s_mismatch_result.append((key, path, vv, nv, pv))
                    heapq.heappop(s_heap)

        for path in s_path:
            new_rule = self.create_rule(act, 's', path[0], path[1], path[2], path[3])

        u_path = []
        for key in self.u_input.keys():
            u_heap = []
            if isinstance(self.u_input[key], list) or isinstance(self.u_input[key], dict):
                heapq.heappush(u_heap, [key])
            else:
                origin = self.fetch_input(self.u_input, *key)
                u_path.append((key, key, origin))
            while u_heap:
                origin = self.fetch_input(self.u_input, *u_heap[0])
                if isinstance(origin, list) or isinstance(origin, dict):
                    for ii, vv in enumerate(origin):
                        # if isinstance(vv, list):
                        #     path = copy.copy(u_heap[0])
                        #     path.append(ii)
                        #     heapq.heappush(u_heap, path)
                        if isinstance(origin, dict):
                            path = copy.copy(u_heap[0])
                            path.append(vv)
                            heapq.heappush(u_heap, path)
                        if isinstance(origin, list):
                            path = copy.copy(u_heap[0])
                            path.append(ii)
                            heapq.heappush(u_heap, path)
                        # if type(origin) is not dict and type(vv) is not list and type(origin) is not list:
                        #     nv = self.fetch_input(post_u_input[key], *u_heap[0])
                        #     u_path.append((key, u_heap[0], origin, nv))
                        #     pv = self.fetch_input(self.state_graph[prediction_state]['u_input'][key], *u_heap[0])
                        #     if nv != pv:
                        #         u_mismatch_result.append((key, u_heap[0], origin, nv, pv))
                else:
                    nv = self.fetch_input(post_u_input, *u_heap[0])
                    u_path.append((key, u_heap[0], origin, nv))
                    pv = self.fetch_input(self.state_graph[prediction_state]['u_input'], *u_heap[0])
                    if nv != pv:
                        u_mismatch_result.append((key, u_heap[0], origin, nv, pv))

                heapq.heappop(u_heap)

        for path in u_path:
            new_rule = self.create_rule(act, 'u', path[0], path[1], path[2], path[3])

        # for key in self.s_input.keys():
        #     s_heap = []
        #     for index, val in enumerate(self.s_input[key]):
        #         if isinstance(val, list):
        #             heapq.heappush(s_heap, [index])
        #         while s_heap:
        #             origin = self.fetch_input(self.s_input[key], *s_heap[0])
        #             check = self.fetch_input(post_s_input[key], *s_heap[0])
        #             try:
        #                 pred = self.fetch_input(self.state_graph[self.prediction_state]['s_input'], *s_heap[0])
        #             except KeyError:
        #                 pred = None
        #             for ii, vv in enumerate(origin):
        #                 path = copy.copy(s_heap[0])
        #                 path.append(ii)
        #                 if isinstance(origin[ii], list):
        #                     heapq.heappush(s_heap, path)
        #                 else:
        #                     try:
        #                         if str((origin[ii], check[ii])) in self.knowledge['s-' + str(key) + '/Value Pairs'].keys():
        #                             found_rule = False
        #                             for item in self.knowledge['s-' + str(key) + '/Value Pairs'][str((origin[ii], check[ii]))]:
        #                                 if item[1] == act:
        #                                     # self.log.debug('UPDATING RULE %s %s %s', path, vv, check[ii])
        #                                     self.update_rule(act, 's', key, path, vv, check[ii], None, item[0])
        #                                     found_rule = True
        #                             if not found_rule:
        #                                 new_rule = self.create_rule(act, 's', key, path, vv, check[ii])
        #                                 # self.log.debug('CREATING RULE not found_rule %s %s %s %s', path, vv, check[ii], new_rule)
        #                         else:
        #                             new_rule = self.create_rule(act, 's', key, path, vv, check[ii])
        #                             # self.log.debug('CREATING RULE no match value pair %s %s %s %s', path, vv, check[ii], new_rule)
        #
        #                     except KeyError:
        #                         new_rule = self.create_rule(act, 's', key, path, vv, check[ii])
        #                         # self.log.debug('CREATING RULE KeyError %s %s %s %s', path, vv, check[ii], new_rule)
        #
        #                     if check[ii] != pred[ii]:
        #                         s_mismatch_result.append((key, path, vv, check[ii]))
        #             heapq.heappop(s_heap)
        #
        # for key in self.u_input.keys():
        #     u_heap = []
        #     if isinstance(self.u_input[key], list) or isinstance(self.u_input[key], dict):
        #         heapq.heappush(u_heap, [key])
        #     while u_heap:
        #         origin = self.fetch_input(self.u_input, *u_heap[0])
        #         check = self.fetch_input(post_u_input, *u_heap[0])
        #         try:
        #             pred = self.fetch_input(self.state_graph[self.prediction_state], *u_heap[0])
        #         except KeyError:
        #             pred = None
        #         if isinstance(origin, list) or isinstance(origin, dict):
        #             for ii, vv in enumerate(origin):
        #                 if isinstance(vv, list):
        #                     path = copy.copy(u_heap[0])
        #                     path.append(ii)
        #                     heapq.heappush(u_heap, path)
        #                 if isinstance(origin, dict):
        #                     path = copy.copy(u_heap[0])
        #                     path.append(vv)
        #                     heapq.heappush(u_heap, path)
        #                 if isinstance(origin, list):
        #                     path = copy.copy(u_heap[0])
        #                     path.append(ii)
        #                     heapq.heappush(u_heap, path)
        #                 if type(origin) is not dict and type(vv) is not list and type(origin) is not list:
        #                     try:
        #                         if str((origin, check)) in self.knowledge['u-' + str(key) + '/Value Pairs'].keys():
        #                             found_rule = False
        #                             for item in self.knowledge['u-' + str(key) + '/Value Pairs'][str((origin, check))]:
        #                                 if item[1] == act:
        #                                     # self.log.debug('UPDATING RULE %s %s %s', path, vv, check[ii])
        #                                     self.update_rule(act, 'u', key, u_heap[0], origin, check, None, item[0])
        #                                     found_rule = True
        #                             if not found_rule:
        #                                 self.create_rule(act, 'u', key, u_heap[0], origin, check)
        #                         else:
        #                             self.create_rule(act, 'u', key, u_heap[0], origin, check)
        #                     except KeyError:
        #                         self.create_rule(act, 'u', key, u_heap[0], origin, check)
        #
        #                     if pred != check:
        #                         u_mismatch_result[key] = u_heap[0]
        #         else:
        #             try:
        #                 if str((origin, check)) in self.knowledge['u-' + str(key) + '/Value Pairs'].keys():
        #                     found_rule = False
        #                     for item in self.knowledge['u-' + str(key) + '/Value Pairs'][str((origin, check))]:
        #                         if item[1] == act:
        #                             # self.log.debug('UPDATING RULE %s %s %s', path, vv, check[ii])
        #                             self.update_rule(act, 'u', key, u_heap[0], origin, check, None, item[0])
        #                             found_rule = True
        #                     if not found_rule:
        #                         self.create_rule(act, 'u', key, u_heap[0], origin, check)
        #                 else:
        #                     self.create_rule(act, 'u', key, u_heap[0], origin, check)
        #             except KeyError:
        #                 self.create_rule(act, 'u', key, u_heap[0], origin, check)
        #
        #             if pred != check:
        #                 u_mismatch_result[key] = u_heap[0]
        #
        #         heapq.heappop(u_heap)

        # If there was a mismatch, clear the action plan
        if s_mismatch_result or u_mismatch_result:
            self.action_plan = []

        # If the prediction does not match the result
        if self.prediction_state != post_state_hash:
            self.action_plan = []

        # self.log.debug('Action Plan: %s', self.action_plan)

        # print('post_capture knowledge %s', self.knowledge)

        # for key in self.knowledge.keys():
        #     # self.log.debug('knowledge key %s', key)
        #     # self.log.debug('knowledge data %s', self.knowledge[key])
        # self.save_state_graph()

        self.save_knowledge('Debug')

        # for key in self.state_graph.keys():
        #     # self.log.debug('state graph key %s', key)
        #     for subkey in self.state_graph[key].keys():
        #         # self.log.debug('state graph subkey %s', subkey)
        #         # self.log.debug('state graph data %s', self.state_graph[key][subkey])
        # self.save_state_graph()

    def make_plan(self, o_state):
        # Search the state graph for the lowest compare based on priority of the task
        # During the search, if an edge in the state graph does not have a high confidence, make a new prediction
        # If the predicted state matches a state in the state graph, update the edge from the current state to the predicted state

        # If the primary task cannot be reached, search for the next priority task
        # If a no priority task opportunity is found at any step, add it to the plan
        # If no task can be reached, find the lowest match ratio along the path to the nearest compare to the primary goal

        # compare format -(edge_outcomes[outcome] * modifiers[outcome] * task[5]), act_key, outcome, finish_task, task_complete)
        self.action_plan = []
        goal_reached = False
        goal_heap = []
        path_heap = dict()
        goal_state = None
        end_search = False
        unknown_act = False

        # Sort tasks by priority
        # for task_key in self.tasks.keys():
        #     for task in self.tasks[task_key]:
        #         if task[5] != 0:
        #             heapq.heappush(task_heap, (task[5], task_key, task))
        #         else:
        #             zero_tasks.append((task_key, task))

        step = 0
        checked_states = set()
        state_heap = []
        # self.log.debug('state graph compare %s', self.state_graph[o_state]['compare'])
        if self.state_graph[o_state]['compare'] is not None:
            heapq.heappush(state_heap, (self.state_graph[o_state]['compare'][0], 0, o_state, self.state_graph[o_state]['compare']))
        else:
            heapq.heappush(state_heap, (0, 0, o_state, None))

        while not goal_reached:
            # self.log.debug('state heap %s', state_heap)
            current_state_data = heapq.heappop(state_heap)
            current_state = current_state_data[2]
            # self.log.debug('current_state_data %s', current_state_data)

            # If the compare of the current state results in task completion, make the completion action the plan
            if current_state_data[3] is not None:
                if current_state_data[3][3]:
                    goal_reached = True
                    goal_state = current_state
                    # print('new goal state 1', goal_state)
                    self.action_plan.insert(0, (path_heap[goal_state][0][3], goal_state, 0, None))
                    break

                # If the only taask is complete, escape planning
                if current_state_data[3][4]:
                    break

            step += 1
            arg_list = dict()
            for act_key in self.state_graph[current_state]['actions'].keys():
                arg_list[act_key] = []
                if isinstance(self.state_graph[current_state]['actions'][act_key], list):
                    for item in self.state_graph[current_state]['actions'][act_key]:
                        arg_list[act_key].append(item)

                if isinstance(self.state_graph[current_state]['actions'][act_key], tuple):
                    arg_list[act_key].append(self.state_graph[current_state]['actions'][act_key])

                if isinstance(self.state_graph[current_state]['actions'][act_key], dict):
                    arg_heap = []
                    for arg_key in self.state_graph[current_state]['actions'][act_key].keys():
                        if isinstance(self.state_graph[current_state]['actions'][act_key][arg_key], list) or isinstance(self.state_graph[current_state]['actions'][act_key][arg_key], dict):
                            heapq.heappush(arg_heap, [arg_key])
                        while arg_heap:
                            arg = self.fetch_input(self.state_graph[current_state]['actions'][act_key], *arg_heap[0])
                            if isinstance(arg, list) or isinstance(arg, dict):
                                for a_i, a_v in enumerate(arg):
                                    if isinstance(arg, dict):
                                        a_path = copy.copy(arg_heap[0])
                                        a_path.append(a_v)
                                        heapq.heappush(arg_heap, a_path)
                                    if isinstance(arg, list):
                                        a_path = copy.copy(arg_heap[0])
                                        a_path.append(a_i)
                                        heapq.heappush(arg_heap, a_path)
                            else:
                                a_path = copy.copy(arg_heap[0])
                                a_path.append(arg)
                                arg_list[act_key].append(a_path)

                            heapq.heappop(arg_heap)

                if self.state_graph[current_state]['actions'][act_key] is None:
                    arg_list[act_key] = ['None']

            act_key_list = list(arg_list.keys())

            # for act_key in arg_list.keys():
            while act_key_list:
                act_key = choice(act_key_list)
                act_key_list.remove(act_key)
                # for act_arg in arg_list[act_key]:
                while arg_list[act_key]:
                    act_arg = choice(arg_list[act_key])
                    arg_list[act_key].remove(act_arg)
                    act = (act_key, act_arg)
                    try:
                        if str(act) not in self.knowledge['actions_taken']:
                            unknown_act = True
                    except KeyError:
                        unknown_act = True

                    if unknown_act:
                        print('AIRIS: Action not yet tried...')
                        self.action_plan.insert(0, (act, current_state, 0, None))
                        # print('new goal state 2', goal_state)
                        # (match ratio, step, heap size, action, current state)
                        # path_heap[goal_state] = [(0, step, 0, act, current_state)]
                        # self.log.debug('unknown action path heap %s', path_heap)
                        goal_reached = True
                        unknown_act = True
                        break

                    # compare format -(edge_outcomes[outcome] * modifiers[outcome] * task[5]), act, outcome, finish_task, task_complete)

                    new_state = self.predict(act, current_state)
                    self.state_graph[new_state]['compare'] = self.compare(new_state, self.tasks)
                    edge_data = self.state_graph[current_state]['edges'][str(act)]['state_heap'][0]

                    # if compare results in an outcome that finishes a task
                    if self.state_graph[current_state]['compare'] is not None:
                        if self.state_graph[current_state]['compare'][3] and self.state_graph[current_state]['compare'][1] == act:
                            self.action_plan.insert(0, (act, edge_data[1], edge_data[0], None))
                            goal_state = edge_data[1]
                            goal_heap = []
                            break
                        else:
                            heapq.heappush(goal_heap, (self.state_graph[current_state]['compare'][0], -edge_data[0], step, edge_data[1], act, current_state))

                    else:
                        heapq.heappush(goal_heap, (0, -edge_data[0], step, edge_data[1], act, current_state))

                if unknown_act:
                    break

                if goal_state is not None:
                    break

            if goal_state is not None:
                break

            if not state_heap:
                break

        # print('path heap', path_heap)
        # print('goal heap', goal_heap)

        # randomize equivalent goal_heap entries
        # if goal_heap:
        #     rand_goal_list = []
        #     best_heap_vals = (goal_heap[0][0], goal_heap[0][1], goal_heap[0][2])
        #     rand_goal_list.append(heapq.heappop(goal_heap))
        #     while goal_heap:
        #         if (goal_heap[0][0], goal_heap[0][1], goal_heap[0][2]) == best_heap_vals:
        #             rand_goal_list.append(heapq.heappop(goal_heap))
        #         else:
        #             break
        #
        #     print('rand_goal_list', rand_goal_list)
        #     shuffle(rand_goal_list)
        #     goal_heap = rand_goal_list

        # print('post rand goal heap', goal_heap)

        if goal_heap and not unknown_act:
            self.action_plan.insert(0, (goal_heap[0][4], goal_heap[0][3], goal_heap[0][1], None))

    def compare(self, state, tasks):
        self.log.debug('COMPARE: Compare state %s', state)
        self.log.debug('COMPARE: Tasks %s', tasks)
        # Tasks can be given a priority. The priority closest to 1 is the highest. A priority of 0 has no priority. Tasks can have equal priority.
        # No priority tasks are opportunistic. It will not seek out these tasks, but will perform them if the opportunity presents.
        # 'Increase' seeks to increase an input(s) by a given amount. If an amount of 0 is given, it will attempt to maximize the increase.
        #   'Increase' : ([structured / unstructured], [input key], [data index / first data index of unstructured list], [index of data to change], [amount], [priority])
        # 'Decrease' seeks to decrease an input(s) by a given amount. If an amount of 0 is given, it will attempt to maximize the decrease.
        #   'Decrease' : ([structured / unstructured], [input key], [data index / first data index of unstructured list], [index of data to change], [amount], [priority])
        # 'Match' seeks to set an input(s) to a given value. This value can be of any type.
        #   'Match' : ([structured / unstructured / action], [input key / action key], [data index / first data index of unstructured list / primary action key], [index of data to match], [value], [priority])

        compare_heap = []
        modifiers = dict()

        # Use the task data to return a difference heap between the current state and the tasks given

        for task_key in tasks.keys():
            for task in tasks[task_key]:
                self.log.debug('COMPARE: checking task %s', task)
                self.log.debug('COMPARE: state u inputs %s', self.state_graph[state]['u_input'])
                finish_task = False
                task_complete = False
                task = tuple(task)
                current_val = None

                if task[0] == 'u':
                    current_val = self.fetch_input(self.state_graph[state]['u_input'][task[1]][task[2]], task[3])
                if task[0] == 's':
                    current_val = self.fetch_input(self.state_graph[state]['s_input'][task[1][task[2]]], task[3])

                self.log.debug('COMPARE: task value location %s %s', task[1], task[2])
                self.log.debug('COMPARE: current value in task location %s', current_val)

                if task_key == 'Match':
                    if current_val == task[4]:
                        task_complete = True
                        heapq.heappush(compare_heap, (0, None, None, finish_task, task_complete))

                # Gather outcome IDs for the task
                try:
                    self.log.debug('COMPARE ERROR: task[0] %s, task[1] %s, task[2] %s', task[0], task[1], task[2])
                    outcome_set = self.knowledge[str(task[0]) + '-' + str(task[1]) + '/outcome_ids']
                    index_set = self.knowledge[str(task[0]) + '-' + str(task[1]) + '/indexes/' + str([task[1], task[2], task[3]])]
                    self.log.debug('COMPARE: outcome set %s', outcome_set)
                    self.log.debug('COMPARE: index set %s', index_set)
                    outcomes = outcome_set & index_set
                except KeyError:
                    outcomes = set()

                for outcome in outcomes:
                    change = None
                    change_type = None
                    abs_values = self.knowledge[str(task[0]) + '-' + str(task[1]) + '/absolute/' + str(outcome)]
                    if len(abs_values) == 1:
                        for change in abs_values:
                            break
                        change_type = 'abs'
                    try:
                        if change is None:
                            rel_values = self.knowledge[str(task[0]) + '-' + str(task[1]) + '/relative/' + str(outcome)]
                            if len(rel_values) == 1:
                                for change in rel_values:
                                    break
                                change_type = 'rel'
                    except KeyError:
                        pass

                    try:
                        if change is None:
                            rat_values = self.knowledge[str(task[0]) + '-' + str(task[1]) + '/ratio/' + str(outcome)]
                            if len(rat_values) == 1:
                                for change in rat_values:
                                    break
                                change_type = 'rat'
                    except KeyError:
                        pass

                    if task_key == 'Match':
                        if change_type == 'abs':
                            if change != task[4]:
                                if type(change) != str:
                                    if change != current_val:
                                        if task[4] != 0:
                                            if change < task[4]:
                                                modifiers[outcome] = change / task[4]
                                            else:
                                                modifiers[outcome] = task[4] / change
                                        else:
                                            modifiers[outcome] = 1 / change
                                    else:
                                        modifiers[outcome] = 0
                                else:
                                    modifiers[outcome] = 0
                            else:
                                modifiers[outcome] = 1
                                finish_task = True

                        if change_type == 'rel':
                            if current_val + change != task[4]:
                                if change != 0:
                                    if task[4] != 0:
                                        if (current_val + change) < task[4]:
                                            modifiers[outcome] = (current_val + change) / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / (current_val + change)
                                    else:
                                        modifiers[outcome] = 1 / (current_val + change)
                                else:
                                    modifiers[outcome] = 0
                            else:
                                modifiers[outcome] = 1
                                finish_task = True

                        if change_type == 'rat':
                            if current_val * change != task[4]:
                                if change != 1:
                                    if task[4] != 0:
                                        if (current_val * change) < task[4]:
                                            modifiers[outcome] = (current_val * change) / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / (current_val * change)
                                    else:
                                        modifiers[outcome] = 1 / (current_val * change)
                                else:
                                    modifiers[outcome] = 0
                            else:
                                modifiers[outcome] = 1
                                finish_task = True

                    if task_key == 'Increase':
                        if change_type == 'abs':
                            if change != current_val:
                                if change > 0:
                                    if task[4] != 0:
                                        if change < task[4]:
                                            modifiers[outcome] = change / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / change
                                    else:
                                        modifiers[outcome] = 1
                                        finish_task = True
                                else:
                                    modifiers[outcome] = 1 / change
                            else:
                                modifiers[outcome] = 0

                        if change_type == 'rel':
                            if change != 0:
                                if change > 0:
                                    if task[4] != 0:
                                        if (current_val + change) < task[4]:
                                            modifiers[outcome] = (current_val + change) / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / (current_val + change)
                                    else:
                                        modifiers[outcome] = 1
                                        finish_task = True
                                else:
                                    modifiers[outcome] = 1 / (current_val + change)
                            else:
                                modifiers[outcome] = 0

                        if change_type == 'rat':
                            if change != 1:
                                if change > 1:
                                    if task[4] != 0:
                                        if (current_val * change) < task[4]:
                                            modifiers[outcome] = (current_val * change) / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / (current_val * change)
                                    else:
                                        modifiers[outcome] = 1
                                        finish_task = True
                                else:
                                    modifiers[outcome] = change
                            else:
                                modifiers[outcome] = 0

                    if task_key == 'Decrease':
                        if change_type == 'abs':
                            if change != current_val:
                                if change < 0:
                                    if task[4] != 0:
                                        if change < task[4]:
                                            modifiers[outcome] = change / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / change
                                    else:
                                        modifiers[outcome] = 1
                                        finish_task = True
                                else:
                                    modifiers[outcome] = 1 / change
                            else:
                                modifiers[outcome] = 0

                        if change_type == 'rel':
                            if change != 0:
                                if change < 0:
                                    if task[4] != 0:
                                        if (current_val + change) < task[4]:
                                            modifiers[outcome] = (current_val + change) / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / (current_val + change)
                                    else:
                                        modifiers[outcome] = 1
                                        finish_task = True
                                else:
                                    modifiers[outcome] = 1 / (current_val + change)
                            else:
                                modifiers[outcome] = 0

                        if change_type == 'rat':
                            if change != 1:
                                if change < 1:
                                    if task[4] != 0:
                                        if (current_val * change) < task[4]:
                                            modifiers[outcome] = (current_val * change) / task[4]
                                        else:
                                            modifiers[outcome] = task[4] / (current_val * change)
                                    else:
                                        modifiers[outcome] = 1
                                        finish_task = True
                                else:
                                    modifiers[outcome] = 1 / change
                            else:
                                modifiers[outcome] = 0

                self.log.debug('COMPARE: modifiers dict %s', modifiers)
                try:
                    for act_key in self.state_graph[state]['edges'].keys():
                        edge_outcomes = self.state_graph[state]['edges'][act_key]['outcomes']
                        for outcome in outcomes:
                            self.log.debug('COMPARE: add to compare heap %s %s %s %s', edge_outcomes[outcome], modifiers[outcome], task[5], [-(edge_outcomes[outcome] * modifiers[outcome] * task[5]), act_key, outcome, finish_task, task_complete])
                            heapq.heappush(compare_heap, (-(edge_outcomes[outcome] * modifiers[outcome] * task[5]), act_key, outcome, finish_task, task_complete))
                except KeyError:
                    pass

        self.log.debug('COMPARE: compare heap %s', compare_heap)
        for item in compare_heap:
            self.log.debug('COMPARE: compare heap item %s', item)

        if compare_heap:
            return compare_heap[0]
        else:
            return None

    def predict(self, act, base_state):
        # Make a prediction of the results of the given action from the given base state
        match_count = 0
        match_total = 0
        predict_s_heap = dict()
        predict_u_heap = dict()
        predict_state = dict()

        predict_state['s_input'] = copy.deepcopy(self.state_graph[base_state]['s_input'])
        predict_state['u_input'] = copy.deepcopy(self.state_graph[base_state]['u_input'])
        predict_state['actions'] = copy.deepcopy(self.state_graph[base_state]['actions'])
        predict_state['applied_rules'] = dict()
        predict_state['all_rules'] = dict()
        predict_state['compare'] = 0
        predict_state['match_ratio'] = 0
        predict_state['match_count'] = 0
        predict_state['match_total'] = 0
        predict_state['edges'] = dict()
        predict_state['outcomes'] = dict()

        self.log.debug('PREDICT: Start prediction %s %s', act, base_state)
        self.log.debug('PREDICT: predict state u_input %s', predict_state['u_input'])

        # Predict structured inputs
        for key in predict_state['s_input'].keys():
            predict_s_heap[key] = dict()
            s_heap = []
            for index, val in enumerate(predict_state['s_input'][key]):
                if isinstance(val, list):
                    heapq.heappush(s_heap, [index])
                while s_heap:
                    item = self.fetch_input(predict_state['s_input'][key], *s_heap[0])
                    for i, v in enumerate(item):
                        path = copy.copy(s_heap[0])
                        path.append(i)
                        if isinstance(item[i], list):
                            heapq.heappush(s_heap, path)
                        else:
                            outcomes = dict()
                            # initialize outcome dict
                            try:
                                for outcome in self.knowledge['s-' + str(key) + '/outcome_ids']:
                                    outcomes[outcome] = 0
                            except KeyError:
                                pass

                            # check indexes
                            try:
                                for outcome in self.knowledge['s-' + str(key) + '/indexes/' + str(path)]:
                                    outcomes[outcome] += 1
                            except KeyError:
                                for outcome in outcomes.keys():
                                    outcomes[outcome] += 1 - (1 / len(self.knowledge['s-' + str(key) + '/indexes/' + str(outcome)]))

                            # check actions
                            try:
                                for outcome in self.knowledge['s-' + str(key) + '/actions/' + str(act)]:
                                    outcomes[outcome] += 1
                            except KeyError:
                                for outcome in outcomes.keys():
                                    outcomes[outcome] += 1 - (1 / len(self.knowledge['s-' + str(key) + '/actions/' + str(act)]))

                            # check unstructured inputs
                            c_u_path = []
                            for c_key in predict_state['u_input'].keys():
                                c_u_heap = []
                                if isinstance(predict_state['u_input'][c_key], list) or isinstance(predict_state['u_input'][c_key], dict):
                                    heapq.heappush(c_u_heap, [c_key])
                                while c_u_heap:
                                    c_origin = self.fetch_input(predict_state['u_input'][c_key], *c_u_heap[0])
                                    if isinstance(c_origin, list) or isinstance(c_origin, dict):
                                        for c_ii, c_vv in enumerate(c_origin):
                                            if isinstance(c_origin, dict):
                                                c_path = copy.copy(c_u_heap[0])
                                                c_path.append(c_vv)
                                                heapq.heappush(c_u_heap, c_path)
                                            if isinstance(c_origin, list):
                                                c_path = copy.copy(c_u_heap[0])
                                                c_path.append(c_ii)
                                                heapq.heappush(c_u_heap, c_path)

                                    else:
                                        c_u_path.append((c_key, c_u_heap[0], c_origin))

                                    heapq.heappop(c_u_heap)

                            for c_path in c_u_path:
                                try:
                                    for outcome in self.knowledge['s-' + str(key) + '/u conditions/' + str(c_path[0]) + '/' + str(c_path[1]) + '/' + str(c_path[2])]:
                                        outcomes[outcome] += 1
                                except KeyError:
                                    for outcome in outcomes.keys():
                                        try:
                                            outcomes[outcome] += 1 - (1 / len(self.knowledge['s-' + str(key) + '/u conditions/' + str(outcome) + '/' + str(c_path[0]) + '/' + str(c_path[1])]))
                                        except KeyError:
                                            pass

                            # Check outcomes for structured inputs
                            c_s_path = []
                            for c_key in self.s_input.keys():
                                c_s_heap = []
                                for c_idx, c_val in enumerate(self.s_input[c_key]):
                                    if isinstance(c_val, list):
                                        heapq.heappush(c_s_heap, [c_idx])
                                    while c_s_heap:
                                        c_origin = self.fetch_input(predict_state['s_input'][c_key], *c_s_heap[0])
                                        for c_ii, c_vv in enumerate(c_origin):
                                            c_path = copy.copy(c_s_heap[0])
                                            c_path.append(c_ii)
                                            if isinstance(c_origin[c_ii], list):
                                                heapq.heappush(c_s_heap, c_path)
                                            else:
                                                c_s_path.append((c_key, c_path, c_vv))
                                        heapq.heappop(c_s_heap)

                                for c_path_origin in c_s_path:
                                    for c_path in c_s_path:
                                        rel = [x - y for x, y in zip(c_path[1], c_path_origin[1])]
                                        try:
                                            for outcome in self.knowledge['s-' + str(key) + '/s conditions rel/' + str(c_path_origin[0]) + '/' + str(c_path_origin[1]) + '/' + str(rel) + '/' + str(c_path[2])]:
                                                outcomes[outcome] += 1
                                        except KeyError:
                                            for outcome in outcomes.keys():
                                                try:
                                                    outcomes[outcome] += 1 - (1 / len(self.knowledge['s-' + str(key) + '/s conditions rel/' + str(outcome) + '/' + str(c_path_origin[0]) + '/' + str(c_path_origin[1]) + '/' + str(rel)]))
                                                except KeyError:
                                                    pass

                            for outcome in outcomes.keys():
                                outcome_heap = []
                                try:
                                    heapq.heappush(outcome_heap, (len(self.knowledge['s-' + str(key) + '/absolute/' + str(outcome)]), 'absolute', self.knowledge['s-' + str(key) + '/absolute/' + str(outcome)]))
                                    try:
                                        heapq.heappush(outcome_heap, (len(self.knowledge['s-' + str(key) + '/relative/' + str(outcome)]), 'relative', self.knowledge['s-' + str(key) + '/relative/' + str(outcome)]))
                                        heapq.heappush(outcome_heap, (len(self.knowledge['s-' + str(key) + '/ratio/' + str(outcome)]), 'ratio', self.knowledge['s-' + str(key) + '/ratio/' + str(outcome)]))
                                    except KeyError:
                                        pass
                                except KeyError:
                                    raise Exception

                                heapq.heappush(predict_s_heap[key][tuple(path)], (-outcomes[outcome], outcome, path, outcome_heap[0], act))

                            predict_state['outcomes'] |= outcomes

                    heapq.heappop(s_heap)

        # Predict unstructured inputs
        u_path = []
        for key in self.u_input.keys():
            u_heap = []
            if isinstance(self.u_input[key], list) or isinstance(self.u_input[key], dict):
                heapq.heappush(u_heap, [key])
            else:
                origin = self.fetch_input(predict_state['u_input'], *key)
                u_path.append((key, key, origin))
            while u_heap:
                origin = self.fetch_input(predict_state['u_input'], *u_heap[0])
                if isinstance(origin, list) or isinstance(origin, dict):
                    for ii, vv in enumerate(origin):
                        if isinstance(origin, dict):
                            path = copy.copy(u_heap[0])
                            path.append(vv)
                            heapq.heappush(u_heap, path)
                        if isinstance(origin, list):
                            path = copy.copy(u_heap[0])
                            path.append(ii)
                            heapq.heappush(u_heap, path)
                else:
                    u_path.append((key, u_heap[0], origin))

                heapq.heappop(u_heap)

        for path in u_path:
            self.log.debug('PREDICT: path in u_path %s', path)
            outcomes = dict()
            key = path[0]
            index = path[1]
            # initialize outcome dict
            try:
                for outcome in self.knowledge['u-' + str(key) + '/outcome_ids']:
                    outcomes[outcome] = 0
            except KeyError:
                pass

            # check indexes
            try:
                for outcome in self.knowledge['u-' + str(key) + '/indexes/' + str(index)]:
                    outcomes[outcome] += 1
            except KeyError:
                for outcome in outcomes.keys():
                    outcomes[outcome] += 1 - (1 / len(self.knowledge['u-' + str(key) + '/indexes/' + str(outcome)]))

            # check actions
            try:
                for outcome in self.knowledge['u-' + str(key) + '/actions/' + str(act)]:
                    outcomes[outcome] += 1
            except KeyError:
                for outcome in outcomes.keys():
                    outcomes[outcome] += 1 - (1 / len(self.knowledge['u-' + str(key) + '/actions/' + str(act)]))

            # check unstructured inputs
            c_u_path = []
            for c_key in predict_state['u_input'].keys():
                c_u_heap = []
                if isinstance(predict_state['u_input'][c_key], list) or isinstance(predict_state['u_input'][c_key], dict):
                    heapq.heappush(c_u_heap, [c_key])
                while c_u_heap:
                    c_origin = self.fetch_input(predict_state['u_input'], *c_u_heap[0])
                    if isinstance(c_origin, list) or isinstance(c_origin, dict):
                        for c_ii, c_vv in enumerate(c_origin):
                            if isinstance(c_origin, dict):
                                c_path = copy.copy(c_u_heap[0])
                                c_path.append(c_vv)
                                heapq.heappush(c_u_heap, c_path)
                            if isinstance(c_origin, list):
                                c_path = copy.copy(c_u_heap[0])
                                c_path.append(c_ii)
                                heapq.heappush(c_u_heap, c_path)

                    else:
                        c_u_path.append((c_key, c_u_heap[0], c_origin))

                    heapq.heappop(c_u_heap)

            for c_path in c_u_path:
                # self.log.debug('PREDICT: c_path in c_u_path %s', c_path)
                try:
                    for outcome in self.knowledge['u-' + str(key) + '/u conditions/' + str(c_path[0]) + '/' + str(c_path[1]) + '/' + str(c_path[2])]:
                        outcomes[outcome] += 1
                except KeyError:
                    for outcome in outcomes.keys():
                        try:
                            outcomes[outcome] += 1 - (1 / len(self.knowledge['u-' + str(key) + '/u conditions/' + str(outcome) + '/' + str(c_path[0]) + '/' + str(c_path[1])]))
                        except KeyError:
                            pass

            # Check outcomes for structured inputs
            c_s_path = []
            for c_key in self.s_input.keys():
                c_s_heap = []
                for c_idx, c_val in enumerate(self.s_input[c_key]):
                    if isinstance(c_val, list):
                        heapq.heappush(c_s_heap, [c_idx])
                    while c_s_heap:
                        c_origin = self.fetch_input(predict_state['s_input'][c_key], *c_s_heap[0])
                        for c_ii, c_vv in enumerate(c_origin):
                            c_path = copy.copy(c_s_heap[0])
                            c_path.append(c_ii)
                            if isinstance(c_origin[c_ii], list):
                                heapq.heappush(c_s_heap, c_path)
                            else:
                                c_s_path.append((c_key, c_path, c_vv))
                        heapq.heappop(c_s_heap)

                for c_path_origin in c_s_path:
                    for c_path in c_s_path:
                        rel = [x - y for x, y in zip(c_path[1], c_path_origin[1])]
                        try:
                            for outcome in self.knowledge['u-' + str(key) + '/s conditions rel/' + str(c_path_origin[0]) + '/' + str(c_path_origin[1]) + '/' + str(rel) + '/' + str(c_path[2])]:
                                outcomes[outcome] += 1
                        except KeyError:
                            for outcome in outcomes.keys():
                                try:
                                    outcomes[outcome] += 1 - (1 / len(self.knowledge['u-' + str(key) + '/s conditions rel/' + str(outcome) + '/' + str(c_path_origin[0]) + '/' + str(c_path_origin[1]) + '/' + str(rel)]))
                                except KeyError:
                                    pass

            for outcome in outcomes.keys():
                outcome_heap = []
                try:
                    # clean result in knowledge
                    for result in self.knowledge['u-' + str(key) + '/absolute/' + str(outcome)]:
                        break
                    heapq.heappush(outcome_heap, (len(self.knowledge['u-' + str(key) + '/absolute/' + str(outcome)]), 'absolute', result))
                    try:
                        for result in self.knowledge['u-' + str(key) + '/relative/' + str(outcome)]:
                            break
                        heapq.heappush(outcome_heap, (len(self.knowledge['u-' + str(key) + '/relative/' + str(outcome)]), 'relative', result))

                        for result in self.knowledge['u-' + str(key) + '/ratio/' + str(outcome)]:
                            break
                        heapq.heappush(outcome_heap, (len(self.knowledge['u-' + str(key) + '/ratio/' + str(outcome)]), 'ratio', result))
                    except KeyError:
                        pass
                except KeyError:
                    raise Exception

                # self.log.debug('PREDICT: outcome heap %s', outcome_heap)
                try:
                    heapq.heappush(predict_u_heap[key][tuple(index)], (-outcomes[outcome], outcome, index, outcome_heap[0], act))
                except KeyError:
                    predict_u_heap[key] = dict()
                    predict_u_heap[key][tuple(index)] = []
                    heapq.heappush(predict_u_heap[key][tuple(index)], (-outcomes[outcome], outcome, index, outcome_heap[0], act))

            predict_state['outcomes'] |= outcomes

        # Predict actions (TODO)

        # Apply best predicted changes to predict state

        self.log.debug('PREDICT: predict state outcomes dict %s', predict_state['outcomes'])

        # Apply structured changes
        for key in predict_s_heap.keys():
            for path in predict_s_heap[key].keys():
                try:
                    predict_state['all_rules'][key][str(path)] = copy.deepcopy(predict_s_heap[key][path])
                except KeyError:
                    predict_state['all_rules'][key] = dict()
                    predict_state['all_rules'][key][str(path)] = copy.deepcopy(predict_s_heap[key][path])
                predict_state['match_total'] += 1
                data = heapq.heappop(predict_s_heap[key][path])
                try:
                    predict_state['applied_rules'][key][str(path)] = data
                except KeyError:
                    predict_state['applied_rules'][key] = dict()
                    predict_state['applied_rules'][key][str(path)] = data
                predict_state['match_count'] += -data[0]
                *head, last = path
                temp = predict_state['s_input'][key]
                for i in head:
                    temp = temp[i]
                if data[3][1] == 'absolute':
                    temp[last] = data[3][2]
                if data[3][1] == 'relative':
                    temp[last] = temp[last] + data[3][2]
                if data[3][1] == 'ratio':
                    temp[last] = temp[last] * data[3][2]

        # Apply unstructured changes
        for key in predict_u_heap.keys():
            for path in predict_u_heap[key].keys():
                try:
                    predict_state['all_rules'][key][str(path)] = copy.deepcopy(predict_u_heap[key][path])
                except KeyError:
                    predict_state['all_rules'][key] = dict()
                    predict_state['all_rules'][key][str(path)] = copy.deepcopy(predict_u_heap[key][path])
                predict_state['match_total'] += 1
                data = heapq.heappop(predict_u_heap[key][path])
                try:
                    predict_state['applied_rules'][key][str(path)] = data
                except KeyError:
                    predict_state['applied_rules'][key] = dict()
                    predict_state['applied_rules'][key][str(path)] = data
                predict_state['match_count'] += -data[0]
                *head, last = path
                head.pop(0)
                temp = predict_state['u_input'][key]
                for i in head:
                    temp = temp[i]
                if data[3][1] == 'absolute':
                    temp[last] = data[3][2]
                if data[3][1] == 'relative':
                    temp[last] = temp[last] + data[3][2]
                if data[3][1] == 'ratio':
                    temp[last] = temp[last] * data[3][2]

        new_hash = self.make_hash(predict_state['s_input'], predict_state['u_input'], predict_state['actions'])

        self.log.debug('PREDICT: new state hash %s', new_hash)

        # Update base_state edges
        if str(act) not in self.state_graph[base_state]['edges'].keys():
            self.state_graph[base_state]['edges'][str(act)] = dict()

        self.state_graph[base_state]['edges'][str(act)]['outcomes'] = copy.deepcopy(predict_state['outcomes'])

        self.log.debug('PREDICT: base state edges outcomes %s', self.state_graph[base_state]['edges'][str(act)]['outcomes'])

        self.state_graph[base_state]['edges'][str(act)][new_hash] = (copy.copy(predict_state['match_count']), copy.deepcopy(predict_state['applied_rules']), copy.deepcopy(predict_state['all_rules']))
        try:
            heapq.heappush(self.state_graph[base_state]['edges'][str(act)]['state_heap'], (-copy.copy(predict_state['match_count']), new_hash))
        except KeyError:
            self.state_graph[base_state]['edges'][str(act)]['state_heap'] = []
            heapq.heappush(self.state_graph[base_state]['edges'][str(act)]['state_heap'], (-copy.copy(predict_state['match_count']), new_hash))

        self.log.debug('PREDICT: base state edges action state_heap %s %s', str(act), self.state_graph[base_state]['edges'][str(act)]['state_heap'])

        # Check if the predicted state already exists in the state graph. If not, create it.
        try:
            find = self.state_graph[new_hash]
            self.log.debug('PREDICT: new hash already exists in state graph')
        except KeyError:
            self.state_graph[new_hash] = dict()
            self.state_graph[new_hash]['s_input'] = copy.deepcopy(predict_state['s_input'])
            self.state_graph[new_hash]['u_input'] = copy.deepcopy(predict_state['u_input'])
            self.state_graph[new_hash]['actions'] = copy.deepcopy(predict_state['actions'])
            self.state_graph[new_hash]['compare'] = self.compare(new_hash, self.tasks)
            self.state_graph[new_hash]['edges'] = dict()
            self.state_graph[new_hash]['grounded'] = False
            self.state_graph[new_hash]['match_total'] = copy.copy(predict_state['match_total'])
            self.log.debug('PREDICT: created new state graph from predicted hash')

        # Return the new state hash key
        return new_hash

    def create_rule(self, act, input_type, key, index, pre_val, post_val):
        # Create a new rule for the given input and performed action
        new_rule = str(uuid.uuid4())[:6]

        try:
            self.knowledge['actions_taken'].add(str(act))
        except KeyError:
            self.knowledge['actions_taken'] = {str(act)}

        try:
            self.knowledge['action_updates'][str(act)] = 0
        except KeyError:
            self.knowledge['action_updates'] = dict()
            self.knowledge['action_updates'][str(act)] = 0

        # See if a unique outcome already exists. If so, then do not create a new rule
        try:
            update = False
            for outcome_id in self.knowledge[input_type + '-' + str(key) + '/outcome_ids']:
                abs_values = self.knowledge[input_type + '-' + str(key) + '/absolute/' + str(outcome_id)]
                if len(abs_values) == 1 and post_val in abs_values:
                    print('error abs: ', abs_values, post_val, outcome_id)
                    self.update_rule(act, input_type, key, index, pre_val, post_val, outcome_id)
                    update = True
                if type(post_val) != str:
                    rel_values = self.knowledge[input_type + '-' + str(key) + '/relative/' + str(outcome_id)]
                    if len(rel_values) == 1 and post_val - pre_val in rel_values:
                        print('error rel: ', abs_values, post_val, outcome_id)
                        self.update_rule(act, input_type, key, index, pre_val, post_val, outcome_id)
                        update = True
                    if pre_val != 0:
                        rat_values = self.knowledge[input_type + '-' + str(key) + '/ratio/' + str(outcome_id)]
                        if len(rat_values) == 1 and post_val / pre_val in rat_values:
                            print('error: ratio', abs_values, post_val, outcome_id)
                            self.update_rule(act, input_type, key, index, pre_val, post_val, outcome_id)
                            update = True

                if update:
                    return None
        except KeyError:
            pass

        # Populate outcomes with new rule id
        try:
            self.knowledge[input_type + '-' + str(key) + '/outcome_ids'] = set(self.knowledge[input_type + '-' + str(key) + '/outcome_ids'])
            self.knowledge[input_type + '-' + str(key) + '/outcome_ids'].add(new_rule)
        except KeyError:
            self.knowledge[input_type + '-' + str(key) + '/outcome_ids'] = {new_rule}
            
        

        self.knowledge[input_type + '-' + str(key) + '/absolute/' + str(new_rule)] = {post_val}
        if type(post_val) != str:
            self.knowledge[input_type + '-' + str(key) + '/relative/' + str(new_rule)] = {post_val - pre_val}
            if pre_val != 0:
                self.knowledge[input_type + '-' + str(key) + '/ratio/' + str(new_rule)] = {post_val / pre_val}

        # Add index of change
        try:
            self.knowledge[input_type + '-' + str(key) + '/indexes/' + str(index)].add(new_rule)
        except KeyError:
            self.knowledge[input_type + '-' + str(key) + '/indexes/' + str(index)] = {new_rule}

        self.knowledge[input_type + '-' + str(key) + '/indexes/' + str(new_rule)] = {str(index)}

        # Add action
        try:
            self.knowledge[input_type + '-' + str(key) + '/actions/' + str(act)].add(new_rule)
        except KeyError:
            self.knowledge[input_type + '-' + str(key) + '/actions/' + str(act)] = {new_rule}

        self.knowledge[input_type + '-' + str(key) + '/actions/' + str(new_rule)] = {str(act)}

        # Go through all unstructured inputs and record conditions
        u_path = []
        for key in self.u_input.keys():
            u_heap = []
            if isinstance(self.u_input[key], list) or isinstance(self.u_input[key], dict):
                heapq.heappush(u_heap, [key])
            else:
                origin = self.fetch_input(self.u_input, *key)
                u_path.append((key, key, origin))
            while u_heap:
                origin = self.fetch_input(self.u_input, *u_heap[0])
                if isinstance(origin, list) or isinstance(origin, dict):
                    for ii, vv in enumerate(origin):
                        # if isinstance(vv, list):
                        #     path = copy.copy(u_heap[0])
                        #     path.append(ii)
                        #     heapq.heappush(u_heap, path)
                        if isinstance(origin, dict):
                            path = copy.copy(u_heap[0])
                            path.append(vv)
                            heapq.heappush(u_heap, path)
                        if isinstance(origin, list):
                            path = copy.copy(u_heap[0])
                            path.append(ii)
                            heapq.heappush(u_heap, path)
                        # if type(origin) is not dict and type(vv) is not list and type(origin) is not list:
                        #     u_path.append((key, u_heap[0], origin))
                else:
                    u_path.append((key, u_heap[0], origin))

                heapq.heappop(u_heap)

        for path in u_path:
            try:
                self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(path[0]) + '/' + str(path[1]) + '/' + str(path[2])].add(new_rule)
            except KeyError:
                self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(path[0]) + '/' + str(path[1]) + '/' + str(path[2])] = {new_rule}

            self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(new_rule) + '/' + str(path[0]) + '/' + str(path[1])] = {str(path[2])}

        # Go through all structured inputs and record conditions
        s_path = []
        for key in self.s_input.keys():
            s_heap = []
            for idx, val in enumerate(self.s_input[key]):
                if isinstance(val, list):
                    heapq.heappush(s_heap, [idx])
                while s_heap:
                    origin = self.fetch_input(self.s_input[key], *s_heap[0])
                    for ii, vv in enumerate(origin):
                        path = copy.copy(s_heap[0])
                        path.append(ii)
                        if isinstance(origin[ii], list):
                            heapq.heappush(s_heap, path)
                        else:
                            s_path.append((key, path, vv))
                    heapq.heappop(s_heap)

            for path_origin in s_path:
                for path in s_path:
                    rel = [x - y for x, y in zip(path[1], path_origin[1])]
                    try:
                        self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel) + '/' + str(path[2])].add(new_rule)
                    except KeyError:
                        self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel) + '/' + str(path[2])] = {new_rule}

                    self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(new_rule) + '/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel)] = {str(path[2])}

        print('created rule', new_rule)
        for item in self.knowledge:
            print('after rule creation', item, ' | ', self.knowledge[item])

        return new_rule

    def update_rule(self, act, input_type, key, index, pre_val, post_val, rule):

        self.knowledge['action_updates'][str(act)] += 1

        for item in self.knowledge:
            print('pre update knowledge', item, ' | ', self.knowledge[item])

        print('here 1')

        print('update error', input_type, key, rule, post_val)
        self.knowledge[input_type + '-' + str(key) + '/absolute/' + str(rule)].add(post_val)
        print('here 1.1')
        if type(post_val) != str:
            self.knowledge[input_type + '-' + str(key) + '/relative/' + str(rule)].add(post_val - pre_val)
            print('here 1.2')
            if pre_val != 0:
                try:
                    self.knowledge[input_type + '-' + str(key) + '/ratio/' + str(rule)].add(post_val / pre_val)
                except KeyError:
                    self.knowledge[input_type + '-' + str(key) + '/ratio/' + str(rule)] = {post_val / pre_val}

        print('here 2')

        try:
            self.knowledge[input_type + '-' + str(key) + '/indexes/' + str(index)].add(rule)
        except KeyError:
            self.knowledge[input_type + '-' + str(key) + '/indexes/' + str(index)] = {rule}

        self.knowledge[input_type + '-' + str(key) + '/indexes/' + str(rule)].add(str(index))

        print('here 3')

        try:
            self.knowledge[input_type + '-' + str(key) + '/actions/' + str(act)].add(rule)
        except KeyError:
            self.knowledge[input_type + '-' + str(key) + '/actions/' + str(act)] = {rule}

        self.knowledge[input_type + '-' + str(key) + '/actions/' + str(rule)].add(str(act))

        print('here 4')

        s_path = []
        for key in self.s_input.keys():
            s_heap = []
            for idx, val in enumerate(self.s_input[key]):
                if isinstance(val, list):
                    heapq.heappush(s_heap, [idx])
                while s_heap:
                    origin = self.fetch_input(self.s_input[key], *s_heap[0])
                    for ii, vv in enumerate(origin):
                        path = copy.copy(s_heap[0])
                        path.append(ii)
                        if isinstance(origin[ii], list):
                            heapq.heappush(s_heap, path)
                        else:
                            s_path.append((key, path, vv))
                    heapq.heappop(s_heap)

            for path_origin in s_path:
                for path in s_path:
                    rel = [x - y for x, y in zip(path[1], path_origin[1])]
                    try:
                        self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel) + '/' + str(path[2])].add(rule)
                    except KeyError:
                        self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel) + '/' + str(path[2])] = {rule}

                    try:
                        self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(rule) + '/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel)].add(str(path[2]))
                    except KeyError:
                        self.knowledge[input_type + '-' + str(key) + '/s conditions rel/' + str(rule) + '/' + str(path_origin[0]) + '/' + str(path_origin[1]) + '/' + str(rel)] = {str(path[2])}

        print('here 5')

        u_path = []
        for key in self.u_input.keys():
            u_heap = []
            if isinstance(self.u_input[key], list) or isinstance(self.u_input[key], dict):
                heapq.heappush(u_heap, [key])
            else:
                origin = self.fetch_input(self.u_input, *key)
                u_path.append((key, key, origin))
            while u_heap:
                origin = self.fetch_input(self.u_input, *u_heap[0])
                if isinstance(origin, list) or isinstance(origin, dict):
                    for ii, vv in enumerate(origin):
                        # if isinstance(vv, list):
                        #     path = copy.copy(u_heap[0])
                        #     path.append(ii)
                        #     heapq.heappush(u_heap, path)
                        if isinstance(origin, dict):
                            path = copy.copy(u_heap[0])
                            path.append(vv)
                            heapq.heappush(u_heap, path)
                        if isinstance(origin, list):
                            path = copy.copy(u_heap[0])
                            path.append(ii)
                            heapq.heappush(u_heap, path)
                        # if type(origin) is not dict and type(vv) is not list and type(origin) is not list:
                        #     u_path.append((key, u_heap[0], origin))
                else:
                    u_path.append((key, u_heap[0], origin))

                heapq.heappop(u_heap)

        for path in u_path:
            try:
                self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(path[0]) + '/' + str(path[1]) + '/' + str(path[2])].add(rule)
            except KeyError:
                self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(path[0]) + '/' + str(path[1]) + '/' + str(path[2])] = {rule}

            try:
                self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(rule) + '/' + str(path[0]) + '/' + str(path[1])].add(str(path[2]))
            except KeyError:
                self.knowledge[input_type + '-' + str(key) + '/u conditions/' + str(rule) + '/' + str(path[0]) + '/' + str(path[1])] = {str(path[2])}

        for item in self.knowledge:
            print('pos update knowledge', item, ' | ', self.knowledge[item])


    def save_knowledge(self, fname):
        with open(fname + '.json', 'w') as file: #Enable to save data to file
            file.write(json.dumps(self.knowledge, indent=4, default=serialize_sets))
        # Save the knowledge

    def save_state_graph(self):
        # with open(fname + '.json', 'w') as file: #Enable to save data to file
        #     file.write(json.dumps(self.state_graph, indent=4))
        return json.dumps(self.state_graph, indent=4)
        # Save the state graph

    def make_hash(self, s_data, u_data, actions):
        hash_string = ''
        for key in sorted(s_data.keys()):
            hash_string += str(s_data[key])
        for key in sorted(u_data.keys()):
            hash_string += str(u_data[key])
        for key in sorted(actions.keys()):
            if actions[key] is not None:
                hash_string += str(actions[key])
            else:
                hash_string += 'None'

        return hashlib.md5(hash_string.encode()).hexdigest()

    def fetch_input(self, arr, *indices):
        arr_copy = copy.deepcopy(arr)
        return reduce(lambda a, i: a[i], indices, arr_copy)